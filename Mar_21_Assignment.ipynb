{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871bd5dc",
   "metadata": {},
   "source": [
    "### Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you might choose one over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8b4d8",
   "metadata": {},
   "source": [
    "Ordinal Encoding and Label Encoding are two techniques for converting categorical variables into numerical values. Ordinal Encoding assigns an integer value to each category based on its order or ranking, such as “low”, “medium”, “high”. Label Encoding assigns an integer value to each category arbitrarily, such as “red” is 1, “green” is 2, and “blue” is 312.\n",
    "\n",
    "You might choose Ordinal Encoding when the categorical variable has an inherent order or ranking, such as education level or customer satisfaction. You might choose Label Encoding when encoding the target variable, especially for categorical variables with no inherent order, such as color or animal.\n",
    "\n",
    "Some additional sentences that could be added if the screen size was not limited are:\n",
    "\n",
    "However, Label Encoding can also introduce a problem of ordinality when there is none, such as implying that blue is greater than green or red. This can affect some machine learning algorithms that assume a linear relationship between the features and the target.\n",
    "One-Hot Encoding is another technique that can overcome this problem by creating a binary vector for each category, such as [1,0,0] for red, [0,1,0] for green, and [0,0,1] for blue. This avoids imposing any order or ranking on the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910db8e",
   "metadata": {},
   "source": [
    "### Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in a machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f621f4",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding is a technique that encodes categorical variables based on the mean of the target variable for each category. The categories are then ordered by the mean value and assigned an integer value accordingly. For example, if we have a categorical variable “city” and a target variable “salary”, we can calculate the mean salary for each city and then assign an integer value to each city based on the mean salary, such as 1 for the lowest mean salary and 4 for the highest mean salary.\n",
    "\n",
    "You might use this technique when you have a categorical variable that has a strong relationship with the target variable, such as city and salary, or when you want to preserve the ordinality of the target variable, such as low, medium, and high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9341bcd",
   "metadata": {},
   "source": [
    "### Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b38966",
   "metadata": {},
   "source": [
    "Covariance is a measure of the relationship between two random variables. It evaluates how much the variables change together, or how they covary12. Covariance is important in statistical analysis because it can help to understand the correlation, causation, and dependence between variables, which can be useful for research, economics, and finance23.\n",
    "Covariance is calculated by analyzing the deviations from the expected or mean values of the two variables, multiplying them for each pair of observations, and then dividing the sum by the number of observations or degrees of freedom14. The formula for covariance is:\n",
    "Cov(X,Y)=∑(Xi​−Xˉ)(Yi−Yˉ)/n\n",
    "where X and Y are the two random variables, Xi​ and Yi​ are the observed values, Xˉ and Yˉ are the mean values, and n is the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a23e5",
   "metadata": {},
   "source": [
    "### Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. Show your code and explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377dfd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suraj Singh\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>Material</th>\n",
       "      <th>Encoded_Material</th>\n",
       "      <th>Color_blue</th>\n",
       "      <th>Color_green</th>\n",
       "      <th>Color_red</th>\n",
       "      <th>Encoded_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>small</td>\n",
       "      <td>wood</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>medium</td>\n",
       "      <td>metal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>large</td>\n",
       "      <td>plastic</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color    Size Material  Encoded_Material  Color_blue  Color_green  Color_red  Encoded_Size\n",
       "0    red   small     wood                 2         0.0          0.0        1.0           0.0\n",
       "1  green  medium    metal                 0         0.0          1.0        0.0           1.0\n",
       "2   blue   large  plastic                 1         1.0          0.0        0.0           2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Color':['red', 'green', 'blue'], 'Size':['small', 'medium','large'], 'Material':['wood','metal','plastic']})\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoded = oh_encoder.fit_transform(df[['Color']]).toarray()\n",
    "oh_encoded_df = pd.DataFrame(oh_encoded, columns=oh_encoder.get_feature_names_out())\n",
    "\n",
    "la_encoder = LabelEncoder()\n",
    "la_encoded = la_encoder.fit_transform(df[['Material']])\n",
    "la_encoded_df = pd.DataFrame(la_encoded, columns=['Encoded_Material'])\n",
    "\n",
    "or_encoder = OrdinalEncoder(categories=[['small','medium','large']])\n",
    "or_encoded = or_encoder.fit_transform(df[['Size']])\n",
    "or_encoded_df = pd.DataFrame(or_encoded, columns=['Encoded_Size'])\n",
    "\n",
    "pd.concat([df, la_encoded_df,oh_encoded_df,or_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2761e2",
   "metadata": {},
   "source": [
    "### Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education level. Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3e4e3",
   "metadata": {},
   "source": [
    "The covariance matrix is a square matrix that shows the covariance between each pair of variables in a dataset. It can be calculated using the formula:\n",
    "Cov(X,Y) = ∑(Xi​−Xˉ)(Yi​−Yˉ)/n\n",
    "where X and Y are the two variables, Xi​ and Yi​ are the observed values, Xˉ and Yˉ are the mean values, and n is the number of observations.\n",
    "For a dataset with three variables: Age, Income, and Education level, the covariance matrix would have three rows and three columns, with the diagonal elements representing the variance of each variable, and the off-diagonal elements representing the covariance between each pair of variables. The covariance matrix would look like this:\n",
    "\n",
    "Var(Age)              |       Cov(Age,Income)        |       Cov(Age, Education)\n",
    "Cov(Age,Income)       |       Var(Income)            |       Cov(Income, Education)\n",
    "Cov(Age,Education)    |      Cov(Income,Education)   |       Var(Education)\n",
    "\n",
    "The covariance matrix can be used to understand the relationships between the variables in a dataset. A positive covariance indicates that two variables tend to increase or decrease together, while a negative covariance indicates that two variables tend to move in opposite directions. A zero covariance indicates that two variables are independent or have no linear relationship. The magnitude of the covariance reflects the strength of the relationship, with higher values indicating stronger relationships. However, the covariance is not standardized and depends on the scale of the variables, so it may not be comparable across different datasets or variables. In such cases, the correlation coefficient may be more appropriate as it is normalized between -1 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c7cb5",
   "metadata": {},
   "source": [
    "### Q6. You are working on a machine learning project with a dataset containing several categorical variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for each variable, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c9b7b",
   "metadata": {},
   "source": [
    "There are different encoding methods for categorical variables, depending on the type and number of categories, the relationship between the categories, and the machine learning algorithm to be used. Some of the common encoding methods are:\n",
    "\n",
    "- Integer Encoding: Where each unique label is mapped to an integer. This method is suitable for ordinal variables, where the categories have a natural order or hierarchy, such as Education Level. For example, High School can be encoded as 1, Bachelor's as 2, Master's as 3, and PhD as 4. This method preserves the ordinality of the variable and reduces the dimensionality of the data. However, it may also introduce an artificial distance or magnitude between the categories that may not reflect their actual relationship.\n",
    "- One Hot Encoding: Where each label is mapped to a binary vector. This method is suitable for nominal variables, where the categories have no inherent order or hierarchy, such as Gender or Employment Status. For example, Male can be encoded as [1,0] and Female as [0,1], or Unemployed as [1,0,0], Part-Time as [0,1,0], and Full-Time as [0,0,1]. This method eliminates the problem of artificial distance or magnitude between the categories and creates a clear distinction between them. However, it also increases the dimensionality of the data and may cause sparsity or multicollinearity issues.\n",
    "- Learned Embedding: Where a distributed representation of the categories is learned. This method is suitable for high-cardinality variables, where the number of categories is large and may not fit into memory or cause overfitting issues. For example, a variable such as City or Country may have hundreds or thousands of unique values that cannot be easily encoded by integer or one hot encoding. In this case, a learned embedding can reduce the dimensionality of the data and capture the semantic similarity or relationship between the categories. This method requires a deep learning model that can learn the optimal embedding for each category based on the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed019c",
   "metadata": {},
   "source": [
    "### Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/East/West). Calculate the covariance between each pair of variables and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f71761",
   "metadata": {},
   "source": [
    "To calculate the covariance between each pair of variables, we need to first encode the categorical variables using integer encoding. For example, we can assign the following values to the categories:\n",
    "\n",
    "- Weather Condition: Sunny = 1, Cloudy = 2, Rainy = 3\n",
    "- Wind Direction: North = 1, South = 2, East = 3, West = 4\n",
    "\n",
    "Then, we can use the same formula as before to calculate the covariance matrix:\n",
    "\n",
    "$$\\text{Cov}(X,Y) = \\frac{\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{n}$$\n",
    "\n",
    "The covariance matrix would have four rows and four columns, with each element representing the covariance between each pair of variables. The covariance matrix would look something like this:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "\\text{Var}(Temperature) & \\text{Cov}(Temperature, Humidity) & \\text{Cov}(Temperature, Weather) & \\text{Cov}(Temperature, Wind) \\\\\n",
    "\\text{Cov}(Temperature, Humidity) & \\text{Var}(Humidity) & \\text{Cov}(Humidity, Weather) & \\text{Cov}(Humidity, Wind) \\\\\n",
    "\\text{Cov}(Temperature, Weather) & \\text{Cov}(Humidity, Weather) & \\text{Var}(Weather) & \\text{Cov}(Weather, Wind) \\\\\n",
    "\\text{Cov}(Temperature, Wind) & \\text{Cov}(Humidity, Wind) & \\text{Cov}(Weather, Wind) & \\text{Var}(Wind)\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The interpretation of the results would depend on the actual values of the covariance matrix. However, some general rules are:\n",
    "\n",
    "- A positive covariance indicates that two variables tend to increase or decrease together. For example, if the covariance between Temperature and Humidity is positive, it means that higher temperatures are associated with higher humidity levels and vice versa.\n",
    "- A negative covariance indicates that two variables tend to move in opposite directions. For example, if the covariance between Temperature and Weather is negative, it means that higher temperatures are associated with lower weather conditions (such as sunny versus rainy) and vice versa.\n",
    "- A zero covariance indicates that two variables are independent or have no linear relationship. For example, if the covariance between Temperature and Wind is zero, it means that temperature does not depend on wind direction or vice versa.\n",
    "- The magnitude of the covariance reflects the strength of the relationship, with higher values indicating stronger relationships. However, the covariance is not standardized and depends on the scale of the variables, so it may not be comparable across different datasets or variables. In such cases, the correlation coefficient may be more appropriate as it is normalized between -1 and 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
