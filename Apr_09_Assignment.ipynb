{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5020047",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef3983",
   "metadata": {},
   "source": [
    "Bayes' theorem is a mathematical formula used to determine the conditional probability of events¹. It describes the probability of an event based on prior knowledge of the conditions that might be relevant to the event². The theorem is named after Thomas Bayes, an English statistician³.\n",
    "\n",
    "The formula for Bayes' theorem is given by:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is the probability of condition when event A is occurring while event B has already occurred.\n",
    "- $P(B|A)$ is the probability of event B occurring when event A has already occurred.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of events A and B, respectively.\n",
    "\n",
    "Bayes' theorem can be used to update the probabilities of hypotheses when given evidence⁴. It follows from the axioms of conditional probability and can be used to reason about a wide range of problems involving belief updates⁴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5b3c3",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0add25",
   "metadata": {},
   "source": [
    "The formula for **Bayes' theorem** is given by:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is the probability of condition when event A is occurring while event B has already occurred.\n",
    "- $P(B|A)$ is the probability of event B occurring when event A has already occurred.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of events A and B, respectively¹.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58219c9a",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8208df4",
   "metadata": {},
   "source": [
    "**Bayes' theorem** has numerous applications across various fields. Here are a few practical applications:\n",
    "\n",
    "1. **Naive Bayes' Classifiers**: Naive Bayes' classifiers are widely used in **text classification**, **spam filtering**, and **sentiment analysis**¹.\n",
    "2. **Discriminant Functions and Decision Surfaces**: Bayes' theorem is employed to create **discriminant functions** and **decision surfaces** for **pattern recognition**¹.\n",
    "3. **Bayesian Parameter Estimation**: Bayes' theorem is used to estimate parameters in a **Bayesian framework**, which is useful in fields such as **machine learning**, **statistics**, and **data science**¹.\n",
    "4. **Genetics**: Bayes' theorem is applied to analyze genetic data, such as determining the probability of a person having a certain genetic condition based on their family history².\n",
    "5. **Finance**: Bayes' theorem is used in finance for tasks such as estimating the probability of default for credit risk assessment³.\n",
    "6. **Epidemiology**: Bayes' theorem plays a crucial role in epidemiology, particularly in the field of disease diagnosis and prediction³.\n",
    "7. **Image Processing**: In image processing, Bayes' theorem is utilized for tasks like image denoising, image segmentation, and object recognition².\n",
    "8. **Forensic Science**: Forensic scientists apply Bayes' theorem to evaluate evidence and calculate the probability of a suspect being guilty or innocent².\n",
    "\n",
    "These are just a few examples of how Bayes' theorem is used in practice. Its versatility makes it an essential tool in various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e1fe5",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d1ece",
   "metadata": {},
   "source": [
    "**Bayes' theorem** and **conditional probability** are closely related concepts in probability theory.\n",
    "\n",
    "**Conditional probability** is the likelihood of an event occurring given that another event has already occurred⁴. It is expressed as the ratio of the probability of the intersection of two events to the probability of the second event¹. For example, the conditional probability of event A given event B is denoted as P(A|B) and calculated as P(A ∩ B) / P(B)¹.\n",
    "\n",
    "**Bayes' theorem** provides a way to update probabilities based on new evidence. It relates the conditional probability of an event A given event B to the conditional probability of event B given event A¹. The formula for Bayes' theorem is:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is the conditional probability of event A given event B.\n",
    "- $P(B|A)$ is the conditional probability of event B given event A.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of events A and B, respectively¹.\n",
    "\n",
    "In summary, Bayes' theorem allows us to update our beliefs about an event based on new evidence, while conditional probability quantifies the likelihood of an event occurring given that another event has already occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca88df0",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0f7d0",
   "metadata": {},
   "source": [
    "The choice of a **Naive Bayes classifier** depends on the nature of the problem and the characteristics of the data. Here are some factors to consider when selecting a specific type of Naive Bayes classifier:\n",
    "\n",
    "1. **Gaussian Naive Bayes**: This classifier assumes that the features follow a **Gaussian distribution**⁵. It is suitable for continuous numerical features.\n",
    "\n",
    "2. **Multinomial Naive Bayes**: This classifier is designed for **count-based** features, such as word frequencies in text classification¹. It is commonly used in **text classification** tasks.\n",
    "\n",
    "3. **Bernoulli Naive Bayes**: This classifier is similar to Multinomial Naive Bayes but assumes that features are **binary variables**¹. It is often used for **binary classification** problems.\n",
    "\n",
    "The choice between these classifiers depends on the nature of your data and the assumptions you can make about the underlying distribution of the features. If your data consists of continuous numerical features, Gaussian Naive Bayes may be appropriate. For count-based or binary features, Multinomial or Bernoulli Naive Bayes can be more suitable, respectively.\n",
    "\n",
    "It's important to note that these classifiers make strong assumptions about the independence of features, which may not always hold in real-world scenarios. Therefore, it's recommended to evaluate different classifiers and compare their performance using appropriate evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1316f553",
   "metadata": {},
   "source": [
    "### Q6 You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "\n",
    "A      3    3    4    4     3    3   3\n",
    "\n",
    "B      2    2    1    2     2    2   3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567fc4f",
   "metadata": {},
   "source": [
    "To predict the class of a new instance with features X1 = 3 and X2 = 4 using **Naive Bayes**, we need to calculate the conditional probabilities for each class.\n",
    "\n",
    "Given the frequency table, we can calculate the conditional probabilities as follows:\n",
    "\n",
    "- For class A:\n",
    "  - P(X1 = 3 | A) = 4/13\n",
    "  - P(X2 = 4 | A) = 3/13\n",
    "- For class B:\n",
    "  - P(X1 = 3 | B) = 1/9\n",
    "  - P(X2 = 4 | B) = 3/9\n",
    "\n",
    "Since we assume equal prior probabilities for each class, the prior probabilities are:\n",
    "- P(A) = P(B) = 1/2\n",
    "\n",
    "To calculate the posterior probabilities, we use Bayes' theorem:\n",
    "\n",
    "- For class A:\n",
    "  - P(A | X1 = 3, X2 = 4) ∝ P(X1 = 3 | A) * P(X2 = 4 | A) * P(A)\n",
    "- For class B:\n",
    "  - P(B | X1 = 3, X2 = 4) ∝ P(X1 = 3 | B) * P(X2 = 4 | B) * P(B)\n",
    "\n",
    "Normalizing these probabilities, we can determine the predicted class.\n",
    "\n",
    "Please note that without additional information or assumptions about the distribution of the features, it is not possible to determine the exact predicted class. The given frequency table only provides limited information about the conditional probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
