{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649f6530",
   "metadata": {},
   "source": [
    "### Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da73a6",
   "metadata": {},
   "source": [
    "Ans\n",
    "Missing values are values that are not stored in a dataset during observations. They can occur due to various reasons, such as \n",
    "human error, sensor failure, or data corruption. It is essential to handle missing values because they can affect the quality \n",
    "and performance of data analysis and machine learning algorithms3. Some algorithms that are not affected by missing values are \n",
    "K-nearest neighbors and Naive Bayes, while others, such as decision trees, have different ways of dealing with them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127b98e",
   "metadata": {},
   "source": [
    "### Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896689db",
   "metadata": {},
   "source": [
    "Ans  \n",
    "Some techniques used to handle missing data are:\n",
    "\n",
    "Deletion: This involves removing the rows or columns that contain missing values. This is the easiest but not the best option, as it can lead to loss of information and bias. For example, to drop rows with missing values in pandas, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509063cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd5f1d",
   "metadata": {},
   "source": [
    "Imputation: This involves replacing the missing values with some other values, such as a constant, a statistic (mean, median, mode), or a value predicted by another algorithm. For example, to impute missing values with the mean in pandas, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27ea4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = sns.load_dataset('titanic')\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220420d5",
   "metadata": {},
   "source": [
    "### Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd82eb96",
   "metadata": {},
   "source": [
    "Ans Imbalanced data is a term used to describe a situation where one target class has a much higher or lower number of observations than another target class in a classification problem. For example, in a dataset of credit card transactions, the class of frauds may be much less frequent than the class of non-frauds1.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to poor performance and accuracy of machine learning models, as they may be biased towards the majority class and ignore the minority class. For example, a model trained on imbalanced data may predict that all transactions are non-frauds, even though some of them are frauds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c128e",
   "metadata": {},
   "source": [
    "### Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcadfc7",
   "metadata": {},
   "source": [
    "And Up-sampling and down-sampling are techniques for changing the sampling rate of a digital signal. Up-sampling increases the number of samples by inserting zeros or interpolating new values between the original samples. Down-sampling decreases the number of samples by discarding some samples or averaging them into fewer values.\n",
    "\n",
    "Up-sampling and down-sampling are required when we want to change the resolution or bandwidth of a signal, or when we want to process signals with different sampling rates together. For example, up-sampling can be used to increase the quality of an audio signal before applying some effects, and down-sampling can be used to reduce the size of an image or a video file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e9ad0",
   "metadata": {},
   "source": [
    "### Q6: What are outliers in a dataset? Why is it essential to handle outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62db69",
   "metadata": {},
   "source": [
    "Ans Outliers are values in a dataset that are very different from most of the other values. They can affect the results of statistical analyses and hypothesis tests. Outliers can be caused by natural variation, measurement errors, or other factors. It is essential to handle outliers because they can skew the mean, standard deviation, and correlation of a dataset. There are different ways to find and deal with outliers, such as using box plots, z-scores, or robust statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7fbb8",
   "metadata": {},
   "source": [
    "### Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327079d2",
   "metadata": {},
   "source": [
    "Ans There are two main approaches to handle missing data: deletion or imputation. Deletion means removing the rows or columns that have missing values, but this can reduce the sample size and introduce bias. Imputation means filling in the missing values with reasonable guesses, such as the mean, median, mode, or a constant value. There are different techniques for imputation, such as using machine learning algorithms, regression models, or nearest neighbors. The choice of technique depends on the type and amount of missing data, and the goal of the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef60c3e",
   "metadata": {},
   "source": [
    "### Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4edfc2",
   "metadata": {},
   "source": [
    "It is not easy to determine if the missing data is random or not, because you cannot observe the missing values or the reasons for their missingness. However, some possible strategies are:\n",
    "\n",
    "Checking if the missing data is missing completely at random (MCAR), which means the probability of missingness is the same for all values and does not depend on any other variable. You can do this by comparing the mean, standard deviation, and distribution of the observed and complete data, or by performing a chi-square test or a t-test.\n",
    "\n",
    "Checking if the missing data is missing at random (MAR), which means the probability of missingness depends on some observed variables but not on the missing values themselves. You can do this by performing a logistic regression with the missing indicator as the outcome and the other variables as predictors, and testing if the coefficients are significant.\n",
    "\n",
    "Checking if the missing data is missing not at random (MNAR), which means the probability of missingness depends on the missing values themselves or some unobserved variables. You can do this by using domain knowledge, sensitivity analysis, or multiple imputation methods to explore different scenarios of missingness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43265e4",
   "metadata": {},
   "source": [
    "### Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f9861",
   "metadata": {},
   "source": [
    "Some strategies to evaluate the performance of your machine learning model on this imbalanced dataset are:\n",
    "\n",
    "Using appropriate metrics that can capture the true positive and false negative rates, such as precision, recall, F1-score, or AUC-ROC. Accuracy is not a good metric because it can be inflated by the majority class.\n",
    "\n",
    "Using cross-validation or stratified sampling to ensure that the train and test sets have the same proportion of classes as the original dataset. This can prevent overfitting or underfitting the model to the minority class.\n",
    "\n",
    "Using resampling techniques such as oversampling the minority class or undersampling the majority class to create a balanced dataset. This can improve the modelâ€™s ability to learn from both classes equally.\n",
    "\n",
    "Using ensemble methods such as bagging, boosting, or stacking to combine multiple models and reduce the variance or bias of the predictions. This can increase the robustness and generalization of the model.\n",
    "\n",
    "Using cost-sensitive learning to assign different weights or penalties to different classes based on their importance or frequency. This can make the model more sensitive to the minority class and less sensitive to the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80ab30",
   "metadata": {},
   "source": [
    "### Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1736e",
   "metadata": {},
   "source": [
    "Some methods to balance the dataset and down-sample the majority class are:\n",
    "\n",
    "Using simple random sampling to select a subset of the majority class that matches the size of the minority class. This can create a balanced dataset, but it may lose some information from the majority class.\n",
    "\n",
    "Using stratified sampling to select a subset of the majority class that preserves the distribution of some important variables or features. This can create a balanced dataset that maintains the representativeness of the majority class.\n",
    "\n",
    "Using cluster-based sampling to group the majority class into clusters based on some similarity measure and then select a subset of clusters to form the balanced dataset. This can reduce the variability within the majority class and increase the diversity of the balanced dataset.\n",
    "\n",
    "Using cost-sensitive learning to assign different weights or penalties to different classes based on their importance or frequency. This can make the model more sensitive to the minority class and less sensitive to the majority class without changing the original dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f994c5",
   "metadata": {},
   "source": [
    "### Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cedb1",
   "metadata": {},
   "source": [
    "Some methods to balance the dataset and up-sample the minority class are:\n",
    "\n",
    "Using simple random sampling with replacement to duplicate observations from the minority class until it matches the size of the majority class. This can create a balanced dataset, but it may introduce overfitting or noise to the minority class.\n",
    "\n",
    "Using synthetic minority oversampling technique (SMOTE) to generate new observations from the minority class by interpolating between existing ones. This can create a balanced dataset that increases the diversity of the minority class.\n",
    "\n",
    "Using adaptive synthetic sampling (ADASYN) to generate new observations from the minority class by using a density distribution as a criterion to decide the number of synthetic samples per existing sample. This can create a balanced dataset that adapts to the underlying data distribution and reduces the learning bias.\n",
    "\n",
    "Using ensemble methods such as bagging, boosting, or stacking to combine multiple models and reduce the variance or bias of the predictions. This can increase the robustness and generalization of the model without changing the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffbab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
